{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name:\n",
    "Student Reg#: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chime\n",
    "chime.notify_exceptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "removable": false
   },
   "source": [
    "In this notebook\n",
    "- The end-to-end crash course of DL is explained as coding.\n",
    "\n",
    "Classroom code: \n",
    "- o64a7np\n",
    "\n",
    "Notebook Authors:\n",
    "- Eng. Ahmed MÃ©twalli\n",
    "- Eng. Alia Elhefny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation:\n",
    "- Download anaconda: https://www.anaconda.com/download/success\n",
    "- Create a new environment called 'DL_SEPT_2024'\n",
    "    - Set Python version 3.11.x\n",
    "    - Install:\n",
    "        - Notebook\n",
    "        - JupyterLab\n",
    "        - VS Code\n",
    "        - CMD Prompt\n",
    "        - Powershell Prompt\n",
    "    - In Python install basic packages (pip install `package`):\n",
    "        - pandas\n",
    "        - numpy\n",
    "        - matplotlib\n",
    "        - seaborn\n",
    "        - tensorflow\n",
    "        - keras\n",
    "        - sklearn\n",
    "        - chime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our traditional Data Science Lifecycle, the main change we have over the course is within the Data Modelling block, where the algorithm used is neural network related, instead of Machine Learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"DS!.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Model of the Perceptron\n",
    "A perceptron a.k.a (Linear Binary Classifier) is a linear classifier that makes decisions based on a linear function. The mathematical model can be represented as follows:\n",
    "\n",
    "1. **Linear Combination:**\n",
    "   $$\n",
    "   z = \\mathbf{W} \\cdot \\mathbf{X} + b\n",
    "   $$\n",
    "   - **W**: Weight vector.\n",
    "   - **X**: Input feature vector.\n",
    "   - **b**: Bias term.\n",
    "\n",
    "2. **Activation Function:**\n",
    "   $$\n",
    "   y = \\text{step}(z)\n",
    "   $$\n",
    "   - The step function is a threshold function that outputs 1 if z >= 0 and 0 otherwise.\n",
    "\n",
    "3. **Perceptron Learning Rule:**\n",
    "   The perceptron adjusts its weights and bias to minimize the classification error using the following rule:\n",
    "   $$\n",
    "   \\Delta \\mathbf{W} = \\eta \\cdot (y_{\\text{true}} - y_{\\text{pred}}) \\cdot \\mathbf{X}\n",
    "   $$\n",
    "   $$\n",
    "   \\Delta b = \\eta \\cdot (y_{\\text{true}} - y_{\\text{pred}})\n",
    "   $$\n",
    "   - **eta**: Learning rate.\n",
    "   - **y_true**: True label of the data point.\n",
    "   - **y_pred**: Predicted label by the perceptron.\n",
    "\n",
    "### Steps to Build the Perceptron Class\n",
    "\n",
    "1. **Initialization:**\n",
    "   - Define a class `Perceptron` with attributes for the learning rate, number of iterations, weights, and bias.\n",
    "   - Initialize the weights and bias to zero.\n",
    "\n",
    "2. **Training (`fit` Method):**\n",
    "   - For each training example, compute the linear combination `z`.\n",
    "   - Apply the activation function to determine the predicted output `y`.\n",
    "   - Update the weights and bias using the perceptron learning rule.\n",
    "\n",
    "3. **Prediction (`predict` Method):**\n",
    "   - Compute the linear combination `z` for given input features.\n",
    "   - Apply the activation function to predict the output.\n",
    "\n",
    "This unit is called Perceptron\n",
    "\n",
    "<img src = \"Perceptron.gif\">\n",
    "\n",
    "### Objective of the Code\n",
    "\n",
    "- **Train the Perceptron** to solve logical operations such as OR, AND, and XOR.\n",
    "- **Visualize Decision Boundaries** to understand how the perceptron separates data points.\n",
    "- **Highlight Limitations** by demonstrating that the perceptron fails to solve non-linearly separable problems like XOR.\n",
    "\n",
    "### Key Takeaways [HINTS]\n",
    "- The perceptron is effective for linearly separable data.\n",
    "- For complex datasets, more sophisticated models like Multi-Layer Perceptrons are required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd # Data manipulation libraries\n",
    "import matplotlib.pyplot as plt # Data visualization\n",
    "\n",
    "# Creation of the perceptron class including all important methods\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate= ..., n_iters= ...):\n",
    "        \n",
    "        self.learning_rate = ...\n",
    "        self.n_iters = ...\n",
    "        self.activation_func = ... \n",
    "        self.weights = ...\n",
    "        self.bias = ...\n",
    "        self.log = pd.DataFrame(columns=[\"Iteration\", \"Weights\", \"Bias\", \"Actual\", \"Predicted\"]) # DF for logging purposes.\n",
    "\n",
    "    def _sigmoid_function(self, x): # fill in the code\n",
    "        return ...\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape # returns the number of samples (rows) and features (columns).\n",
    "        self.weights = ...\n",
    "        self.bias = ...\n",
    "        self._log(0, X, y) # Logging initial weights and bias as 0\n",
    "        # Gradient descent algorithm\n",
    "        for iteration in range(1, self.n_iters + 1): #The outer loop runs for the number of iterations (self.n_iters).\n",
    "            for idx, x_i in enumerate(X): #The inner loop iterates over each sample x_i in the dataset X.\n",
    "                linear_output = ... # Calc. the linear combination of weights and features plus bias.\n",
    "                y_predicted = self.activation_func(...) #Apply activation func.\n",
    "                # Perceptron learning rule update\n",
    "                update = ... # Update rule\n",
    "                self.weights += update * x_i # Equation applied\n",
    "                self.bias += update\n",
    "            # Logger operation\n",
    "            self._log(iteration, X,y ) # Logging weights, bias, and predictions at each iteration\n",
    "\n",
    "    def _log(self, iteration, X, y):\n",
    "        \"\"\"Log the weights and bias for each iteration.\"\"\"\n",
    "        y_predicted = self.predict(X) # Calculate predictions for the current weights and bias\n",
    "        log_entry = pd.DataFrame({\n",
    "            \"Iteration\": [iteration] * len(X), # Repeating the current iteration for each data point\n",
    "            \"Weights\": [self.weights.copy()], # Because weights are stored in array-like so that are mutable \n",
    "            \"Bias\": [self.bias], # Bias is scalar immutable therefore no copy operation added\n",
    "            \"Actual\": y, # Log the actual output\n",
    "            \"Predicted\": y_predicted # Log the predicted output\n",
    "        })\n",
    "        self.log = pd.concat([self.log, log_entry], ignore_index=True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"This function uses the trained weights and bias to predict labels for input data X.\"\"\"\n",
    "        linear_output = ...\n",
    "        y_predicted = self.activation_func(...)\n",
    "        return ...\n",
    "\n",
    "# Utility class for dataset creation and visualization\n",
    "class Utility: #Utility programming-wise covers \n",
    "    @staticmethod #Static method unlike classes with init, it doesn't need to access 'self'\n",
    "    def plot_decision_boundary(X, y, model, title):\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1  #X[:, 0] and X[:, 1] represent the two features in the dataset X.\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 # (+ or - 1) extends the plotting area slightly beyond the points\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), # Helps us to generate the coordinates data from individual arrays\n",
    "                            np.arange(y_min, y_max, 0.01)) # and visualize the decision boundary\n",
    "        # generates values from x_min to x_max with a step of 0.01. This creates a fine grid for smooth plotting.\n",
    "        Z = model.predict(np.c_[xx.ravel(), yy.ravel()]) # Ravel flattens the 2d arrays\n",
    "        Z = Z.reshape(xx.shape) # Z is reshaped back into a 2D same shape as xx and yy for plotting the decision boundary.\n",
    "        plt.contourf(xx, yy, Z, alpha=0.8) # alpha=0.8 parameter controls the transparency of the contour plot.\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o', s=50) # X, y, color, bordercolor, marker, markersize\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "        \n",
    "    @staticmethod\n",
    "    def create_logical_dataset(logical_operator):\n",
    "        if logical_operator == 'OR':\n",
    "            X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "            y = np.array([0, 1, 1, 1])\n",
    "        elif logical_operator == 'AND':\n",
    "            X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "            y = np.array([0, 0, 0, 1])\n",
    "        elif logical_operator == 'XOR':\n",
    "            X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "            y = np.array([0, 1, 1, 0])\n",
    "        else:\n",
    "            raise ValueError(\"Unknown logical operator!\")\n",
    "        \n",
    "        # Create a pandas DataFrame for better visualization\n",
    "        df = pd.DataFrame(X, columns=[\"Feature 1\", \"Feature 2\"])\n",
    "        df[\"Label\"] = y\n",
    "        display(df)\n",
    "        return X, y\n",
    "\n",
    "# Helper function to train and visualize the perceptron on a given dataset\n",
    "class Helper: #Helper generally focused on performing small, specific series of operations (Handling scenarios)\n",
    "    @staticmethod\n",
    "    def train_and_visualize(logical_operator):\n",
    "        X, y = Utility.create_logical_dataset(logical_operator)\n",
    "        perceptron = Perceptron(learning_rate=0.1, n_iters=10)\n",
    "        perceptron.fit(X, y)\n",
    "        Utility.plot_decision_boundary(X, y, perceptron, f'{logical_operator} Perceptron Decision Boundary')\n",
    "        \n",
    "        # Display the weights and bias log in a DataFrame\n",
    "        display(perceptron.log)\n",
    "\n",
    "# OR Problem\n",
    "print(\"Training Perceptron on OR dataset...\")\n",
    "Helper.train_and_visualize('OR')\n",
    "\n",
    "# AND Problem\n",
    "print(\"Training Perceptron on AND dataset...\")\n",
    "Helper.train_and_visualize('AND')\n",
    "\n",
    "# XOR Problem\n",
    "print(\"Training Perceptron on XOR dataset (expected to fail)...\")\n",
    "Helper.train_and_visualize('XOR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "- The perceptron model works perfectly for linearly separable data such as OR and AND, but fails to solve the XOR problem due to its linear decision boundary.\n",
    "- For non-linearly separable data, we need to use more advanced models like Multi-Layer Perceptrons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Terminologies!!:\n",
    "DL:\n",
    "- Epoch: One complete pass through the entire training dataset. This involves processing every sample in the dataset once.\n",
    "- Iteration: In this code, an iteration refers to a single update of the model's parameters. Here, the number of iterations is set to the number of epochs, as each epoch updates the model for every sample in the dataset.\n",
    "\n",
    "Programming:\n",
    "- Utility: Utilities are typically more general-purpose and can be applied in a variety of contexts. They may include operations like file handling, data transformation, or mathematical calculations.\n",
    "- Helper: Helpers are typically more narrowly scoped to support a specific part of an application or module. For example, a \"helper\" might be used to handle string formatting, validate inputs, or perform a small, repetitive task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classwork 1: Solving the XOR Problem with a Multi-Layer Perceptron Using Keras\n",
    "\n",
    "#### Objective:\n",
    "- Implement a Multi-Layer Perceptron (MLP) using Keras to solve the XOR problem.\n",
    "- Understand how to use high-level deep learning libraries for building, training, and evaluating neural networks.\n",
    "\n",
    "#### Steps to Complete the Assignment:\n",
    "\n",
    "#### Hints\n",
    "```python\n",
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Create the XOR inputs and outputs\n",
    "X = np.array(...)\n",
    "y = np.array(...)\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(...))\n",
    "model.add(Dense(...))\n",
    "# Compile the model\n",
    "model.compile(loss='...', optimizer='...', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(..., ..., epochs=...)\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(...)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitocluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
